{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AIM-SR\n",
    "\n",
    "Sign recognition demo using the BrainForge library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from brainforge import Backpropagation, LayerStack\n",
    "from brainforge import layers, optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset can either be downloaded and extracted to this project's data/ folder using the data/get.sh script or you can specify the dataset root below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DATASET_ROOT = \"data/train-52x52\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import streamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [Streamer] - Num train samples: 48000\n",
      " [Streamer] - Num val samples: 12000\n"
     ]
    }
   ],
   "source": [
    "stream = streamer.Stream(root=DATASET_ROOT, split_validation=0.2, image_format=\"channels_first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "The data will be fit by an Artificial Neural Network, more specifically a Fully Convolutional Neural Network, which has a relatively low number of parameters and thus (hopefully) generalizes better than a vanilla CNN with a Dense head.\n",
    "\n",
    "The network weights will be optimized by Gradient Descent on the gradients determined by Backpropagation.\n",
    "\n",
    "The task is a 12-clas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stack = LayerStack(stream.input_shape, layers=[\n",
    "    \n",
    "    layers.ConvLayer(nfilters=16, filterx=5, filtery=5, compiled=True),\n",
    "    layers.PoolLayer(filter_size=2, compiled=True),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "    layers.ConvLayer(nfilters=32, filterx=5, filtery=5, compiled=True),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "    layers.ConvLayer(nfilters=32, filterx=5, filtery=5, compiled=True),\n",
    "    layers.PoolLayer(filter_size=2, compiled=True),\n",
    "    layers.Activation(\"relu\"),\n",
    "\n",
    "    layers.ConvLayer(nfilters=stream.NUM_CLASSES, filterx=5, filtery=5, compiled=True),\n",
    "\n",
    "    layers.GlobalAveragePooling(),\n",
    "    layers.Activation(\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "The training takes about 2-3 hours and the network reaches over 99.9% accuracy on the validation set, which is unnaturally high and is caused probably by validation set which is highly similar to the training set.\n",
    "\n",
    "Below are the parameters for the training. Previous experiments showed that 10 epochs are sufficient to reach convergence on this dataset. The relatively low batch size and high learning rate has ensures the network jumps out of smaller local minima and finds a good optimum with good generalization. Together with the fully convolutional nature of the architecture, this produces sufficient regularization, so no additional regularization was required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 10\n",
    "LEARNING_RATE = 1e-3\n",
    "VALIDATION_INCREASE_FACTOR = 4  # divides steps per epoch and multiplies epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/40\n",
      "Training Progress:   1.2%  cost: 2.4997 accuracy: 0.0533"
     ]
    }
   ],
   "source": [
    "net = Backpropagation(layerstack=stack, cost=\"cxent\", optimizer=optimizers.Adam(LEARNING_RATE))\n",
    "\n",
    "net.fit_generator(stream.iter_subset(\"train\", BATCH_SIZE),\n",
    "                  lessons_per_epoch=stream.steps_per_epoch(\"train\", BATCH_SIZE) // VALIDATION_INCREASE_FACTOR,\n",
    "                  epochs=10 * VALIDATION_INCREASE_FACTOR,\n",
    "                  metrics=[\"acc\"],\n",
    "                  validation=stream.iter_subset(\"val\", BATCH_SIZE),\n",
    "                  validation_steps=stream.steps_per_epoch(\"val\", BATCH_SIZE))\n",
    "\n",
    "# Save the weights as NumPy vector.\n",
    "weights = net.get_weights(unfold=True)\n",
    "np.save(\"AIM-SR-weights.npy\", weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Below we set up some functions to aid testing the network on arbitrary input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NETWORK_WEIGHTS = \"AIM-SR-weights.npy\"\n",
    "\n",
    "stack.set_weights(np.load(NETWORK_WEIGHTS), fold=True)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    x = image / 255.  # Downscale to range 0. - 1.\n",
    "    x = x.transpose((2, 0, 1))  # Convert to channels first\n",
    "    return x[None, ...]  # Add a batch dimension\n",
    "\n",
    "def execute_detection(image):\n",
    "    x = preprocess_image(image)\n",
    "    output = stack.feedforward(x)[0]  # eliminate batch dim\n",
    "    prediction = np.argmax(output, axis=1)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}